g1
summary(lm(Fertility ~ Agriculture + Agriculture : factor(CatholicBin), data = swiss))$coef
n <- 100; t <- rep(c(0, 1), c(n/2, n/2)); x <- c(runif(n/2), runif(n/2));
beta0 <- 0; beta1 <- 2; tau <- 1; sigma <- .2
y <- beta0 + x * beta1 + t * tau + rnorm(n, sd = sigma)
plot(x, y, type = "n", frame = FALSE)
abline(lm(y ~ x), lwd = 2)
abline(h = mean(y[1 : (n/2)]), lwd = 3)
abline(h = mean(y[(n/2 + 1) : n]), lwd = 3)
fit <- lm(y ~ x + t)
abline(coef(fit)[1], coef(fit)[2], lwd = 3)
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2], lwd = 3)
points(x[1 : (n/2)], y[1 : (n/2)], pch = 21, col = "black", bg = "lightblue", cex = 2)
points(x[(n/2 + 1) : n], y[(n/2 + 1) : n], pch = 21, col = "black", bg = "salmon", cex = 2)
n <- 100; t <- rep(c(0, 1), c(n/2, n/2)); x <- c(runif(n/2), runif(n/2));
beta0 <- 0; beta1 <- 2; tau <- 1; sigma <- .2
y <- beta0 + x * beta1 + t * tau + rnorm(n, sd = sigma)
plot(x, y, type = "n", frame = FALSE)
abline(lm(y ~ x), lwd = 2)
abline(h = mean(y[1 : (n/2)]), lwd = 3)
abline(h = mean(y[(n/2 + 1) : n]), lwd = 3)
fit <- lm(y ~ x + t)
abline(coef(fit)[1], coef(fit)[2], lwd = 3)
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2], lwd = 3)
points(x[1 : (n/2)], y[1 : (n/2)], pch = 21, col = "black", bg = "lightblue", cex = 2)
points(x[1 : (n/2)], y[1 : (n/2)], pch = 21, col = "black", bg = "lightblue", cex = 2)
points(x[(n/2 + 1) : n], y[(n/2 + 1) : n], pch = 21, col = "black", bg = "salmon", cex = 2)
install.packages("rgl")
?influence.measures
data(swiss); par(mfrow = c(2, 2))
fit <- lm(Fertility ~ . , data = swiss); plot(fit)
install.packages("car")
library(car)
vif(fit)
sqrt(vif(fit))
fit1 = lm(Fertility~Agriculture, swiss)
fit2 = lm(Fertility~Agriculture+Examination+Education, swiss)
fit3 = lm(Fertility~Agriculture+Examination+Education+Catholic+Infant.Mortality, swiss)
anova(fit1, fit2, fit3)
library(swirl)
swirl()
rgp1()
rgp2()
head(swiss)
mdl <- lm(Fertility~.,swiss)
vif(mdl)
mdl2 <- lm(Fertility~Agriculture+Education+Catholic+Infant.Mortality,swiss)
vif(mdl2)
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm (Fertility ~Agriculture, swiss)
fit3 <- lm (Fertility ~Agriculture+Examination + Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1)-deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail=FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
ravenData
mdl <- glm(ravenWinNum ~ ravenScore,"binomial", ravenData)
predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
confint(mdl)
exp(confint(mdl))
type anova(mdl)
anova(mdl)
qchisq(0.95, 1)
var(rpois(1000, 50))
nxt()
View(hits)
class(hits[,'date'])
as.integer(head(hits[,'date']))
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
confint(mdl, 'date')
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,]
lambda <- mdl$fitted.values[704]
qpois(.95,lambda)
View(hits)
mdl2 <- glm(simplystats ~ date, poisson, hits, offset=log(visits+1))
qpois(.95, mdl2$fitted.values[704])
install.packages("MASS")
library(MASS)
data("shuttle")
?shuttle
view(shuttle)
View(shuttle)
fit <- glm(use ~ wind, binary, shuttle)
fit <- glm(use ~ wind, binomila, shuttle)
fit <- glm(use ~ wind, binomial, shuttle)
summary(fit)
data(shuttle)
new_shuttle=mutate(shuttle,autobin= ifelse(use=='auto',1,0))
logfit = glm(new_shuttle$autobin~factor(new_shuttle$wind)-1,family="binomial")
coeff=summary(logfit)$coeff[,1]
ans=exp(coeff[1]-coeff[2])
ans
library(dplyr)
data(shuttle)
new_shuttle=mutate(shuttle,autobin= ifelse(use=='auto',1,0))
logfit = glm(new_shuttle$autobin~factor(new_shuttle$wind)-1,family="binomial")
coeff=summary(logfit)$coeff[,1]
ans=exp(coeff[1]-coeff[2])
ans
summary(logfit)
logfit = glm(new_shuttle$autobin~factor(new_shuttle$wind),family="binomial")
coeff=summary(logfit)$coeff[,1]
ans=exp(coeff[1]-coeff[2])
factor(new_shuttle$wind)head
ans
logfit = glm(new_shuttle$autobin~factor(new_shuttle$wind)-1,family="binomial")
coeff=summary(logfit)$coeff[,1]
ans=exp(coeff[1]-coeff[2])
ans
logfit = glm(new_shuttle$autobin~factor(new_shuttle$wind)+new_shuttle$magn-1,family="binomial")
coeff=summary(logfit)$coeff[,1]
ans=exp(coeff[1]-coeff[2])
ans
logfit = glm(-new_shuttle$autobin~factor(new_shuttle$wind)-1,family="binomial")
logfit = glm(new_shuttle$autobin-1~factor(new_shuttle$wind)-1,family="binomial")
logfit = glm(1-new_shuttle$autobin-1~factor(new_shuttle$wind)-1,family="binomial")
logfit = glm(1-new_shuttle$autobin~factor(new_shuttle$wind)-1,family="binomial")
summary(logfit)
data("InsectSprays")
head(InsectSprays)
fit <- glm(count~factor(spray),Poisson,InsectSprays)
fit <- glm(count~factor(spray),family = "Poisson",InsectSprays)
fit <- glm(count~factor(spray),family = poisson,InsectSprays)
summary(fit)
fit <- glm(count~factor(spray)-1,family = poisson,InsectSprays)
summary(fit)
exp(fit$coefficients[1,1]- fit$coefficients[2,1])
exp(fit$coef[1,1]- fit$coef[2,1])
exp(summary(fit)$coef[1,1]- summary(fit)$coef[2,1])
2.67/2.73
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
spline_term = x*(x>0)
regr = cbind(1,x,spline_term)
fit = lm(y~regr-1)
yhat = predict(fit)
plot(x,y,frame=FALSE,pch=21,bg='lightblue',cex=2)
lines(x,yhat,col='red',lwd=2)
install.packages("rpart")
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
intrain = createDataPartition(y=segmentationOriginal$Case, p=0.8, list=F)
training = segmentationOriginal[intrain,]
testing = segmentationOriginal[-intrain,]
modFit = train(Case, data=training, method="rpart")
modFit = train(Case ~., data=training, method="rpart")
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
modFit$finalModel
intrain = createDataPartition(y=segmentationOriginal$Case, p=0.6, list=F)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
modFit <- train(Class ~ ., method = "rpart", data = training)
fancyRpartPlot(modFit$finalModel)
intrain = createDataPartition(y=segmentationOriginal$Case, p=0.6, list=F)
training <- segmentationOriginal[intrain, ]
testing <- segmentationOriginal[-intrain, ]
training <- segmentationOriginal[intrain, ]
testing <- segmentationOriginal[-intrain, ]
modFit <- train(Class ~ ., method = "rpart", data = training)
fancyRpartPlot(modFit$finalModel)
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
fancyRpartPlot(modFit$finalModel)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
View(newdata)
View(newdata)
modolive <- train(Area ~ ., method = "rpart", data = olive)
predict(modolive, newdata=newdata)
View(olive)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
View(trainSA)
modheart <- train(chd~age+obesity+tobacco+typea+ldl, family="binomial", method="glm", data="trainSA")
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass = function(values, prediction){sum(((prediction > 0.5) * 1) != values) / length(values)}
missclass(trainsSA$chd, predict(modelSA,newdata=trainSA))
missClass(trainsSA$chd, predict(modelSA,newdata=trainSA))
missClass(trainSA$chd, predict(modelSA,newdata=trainSA))
missClass(testSA$chd, predict(modelSA,newdata=testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test$fy =as.factor(vowel.test$y)
vowel.train$fy =as.factor(vowel.train$y)
View(vowel.test)
install.packages("randomForest")
library(randomForest)
model = randomForest(fy ~., data=vowel.train)
varImp(model)
library(ggplot2);library(caret);library(dplyr)
if (!file.exists("./data/training.csv")) {
download.file(
"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
"./data/training.csv"
)
data <-
read.csv(
"./data/training.csv",
na.strings = c("NA", "#DIV/0!", "")
)
}
if (!file.exists("./data/testing.csv")) {
download.file(
"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
"./data/testing.csv"
)
test <-
read.csv(
"./data/testing.csv",
na.strings = c("NA", "#DIV/0!", "")
)
}
library(ggplot2);library(caret);library(dplyr)
library(ggplot2);library(caret);library(dplyr)
if (!file.exists("./data/training.csv")) {
download.file(
"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
"./data/training.csv"
)
data <-
read.csv(
"./data/training.csv",
na.strings = c("NA", "#DIV/0!", "")
)
}
if (!file.exists("./data/testing.csv")) {
download.file(
"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
"./data/testing.csv"
)
test <-
read.csv(
"./data/testing.csv",
na.strings = c("NA", "#DIV/0!", "")
)
}
set.seed(9125)
inTrain <- createDataPartition(y = data$classe, p = .6, list = F)
data$classe
data
train
dim(train)
if (!file.exists("./data/training.csv")) {
download.file(
"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
"./data/training.csv"
)
}
train <-
read.csv("./data/training.csv",
na.strings = c("NA", "#DIV/0!", ""))
if (!file.exists("./data/testing.csv")) {
download.file(
"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
"./data/testing.csv"
)
}
test <-
read.csv("./data/testing.csv",
na.strings = c("NA", "#DIV/0!", "")
)
set.seed(9125)
inTrain <- createDataPartition(y = train$classe, p = .6, list = F)
training <- train[inTrain,]
validation <- train[-inTrain,]
str(training)
dim(training)
dim(validation)
nsv <- nearZeroVar(training, saveMetrics=TRUE)
nsv
subset(nsv, nzv==TRUE)
subset(nsv, nzv==TRUE || zeroVar==TRUE)
subset(nsv, nzv==TRUE | zeroVar==TRUE)
subset(nsv, nzv==TRUE | zeroVar==TRUE)[1,]
subset(nsv, nzv==TRUE | zeroVar==TRUE)[,1]
subset(nsv, nzv==TRUE | zeroVar==TRUE)
nsv <- nearZeroVar(training, saveMetrics=TRUE)
training <- training[, nsv$zeroVar ==F & nsv$nzv==F]
validation <- validation[, nsv$zeroVar ==F & nsv$nzv==F]
View(nsv)
nsv <- nearZeroVar(training, saveMetrics = TRUE)
training <- training[, -nsv]
nsv <- nearZeroVar(training)
training <- training[, -nsv]
validation <- validation[, -nsv]
nsv
nsv <- nearZeroVar(training, saveMetrics = TRUE)
training <- training[, -nsv]
nsv <- nearZeroVar(training, saveMetrics = TRUE)
training <- training[, -nsv]
View(nsv)
nsv <- nearZeroVar(training, saveMetrics = TRUE)
training <- training[, -nsv]
set.seed(9125)
inTrain <- createDataPartition(y = train$classe, p = .6, list = F)
training <- train[inTrain,]
validation <- train[-inTrain,]
str(training)
dim(training)
dim(validation)
nsv <- nearZeroVar(training, saveMetrics = TRUE)
View(nsv)
nsv <- nearZeroVar(training)
training <- training[, -nsv]
nsv <- nearZeroVar(training, saveMetrics = TRUE)
nsv <- nearZeroVar(training)
training <- training[, -nsv]
validation <- validation[, -nsv]
set.seed(9125)
inTrain <- createDataPartition(y = train$classe, p = .6, list = F)
training <- train[inTrain,]
validation <- train[-inTrain,]
str(training)
dim(training)
dim(validation)
nsv <- nearZeroVar(training)
training <- training[, -nsv]
validation <- validation[, -nsv]
rNas <- colMeans(is.na(training))
rNas
rNas <- rNas[,rNas > .75]
rNas <- rNas[rNas > .75]
training[,rNas[rNas > .75]]
training[,rNas[rNas < .75]]
training
dim(training)
rNas[rNas < .95]
rNas[rNas < .75]
rNas <- colMeans(is.na(training))
training[,rNas[rNas < .75]]
rNas[rNas < .75]
training[,rNas[rNas < .75]]
dim(training)
dim(rNas)
training[,rNas[rNas < 0.75]]
training[,rNas < 0.75]
dim(training[,rNas < 0.75])
rNas <- colMeans(is.na(training))
training<- training [,rNas < .75]
validation <- validation[,rNas < .75]
dim(training)
dim(validation)
View(training)
treeModel <- train (classe ~., data=training, method="rpart")
predTree <- predict(treeModel, newdata=validation, type="class")
treeModel <- train (classe ~., data=training, method="rpart")
treeModel <- train (classe ~., data=training, method="rpart")
predTree <- predict(treeModel, newdata=validation)
confusionMatrix(predTree,validation$classe )
training <- preProcess(training[,-c(1:5)],method="knnImpute")
validation <- preProcess(validation[,-c(1:5)],method="knnImpute")
rNas <- colMeans(is.na(training))
set.seed(9125)
inTrain <- createDataPartition(y = train$classe, p = .6, list = F)
training <- train[inTrain,]
validation <- train[-inTrain,]
str(training)
dim(training)
dim(validation)
nsv <- nearZeroVar(training)
training <- training[, -nsv]
validation <- validation[, -nsv]
rNas <- colMeans(is.na(training))
training<- training [,rNas < .75 | -c (1:5)]
validation <- validation[,rNas < .75]
dim(training)
dim(validation)
nsv <- nearZeroVar(training)
training <- training[, -c(nsv,c(1:5))]
validation <- validation[, -c(nsv,c(1:5))]
rNas <- colMeans(is.na(training))
training<- training [,rNas < .75 ]
validation <- validation[,rNas < .75]
rNas <- colMeans(is.na(training))
training<- training [,rNas < .75 ]
validation <- validation[,rNas < .75]
dim(training)
dim(validation)
treeModel <- train (classe ~ ., data = training, method = "rpart")
predTree <- predict(treeModel, newdata = validation)
confusionMatrix(predTree, validation$classe)
library(ggplot2);library(caret);library(dplyr);libray(rpart)
library(ggplot2);library(caret);library(dplyr);library(rpart)
treeModel <- rpart(classe ~., data=training)
predTree <- predict(treeModel, newdata = validation)
confusionMatrix(predTree, validation$classe)
treeModel <- rpart(classe ~., data=training, method = "class")
predTree <- predict(treeModel, newdata = validation)
confusionMatrix(predTree, validation$classe)
treeModel <- rpart(classe ~ ., data=training, method="class")
predTree <- predict(treeModel, newdata = validation)
confusionMatrix(predTree, validation$classe)
View(training)
treeModel <- rpart(classe ~ ., data=training, method="class")
predTree <- predict(treeModel, newdata = validation, type="class")
confusionMatrix(predTree, validation$classe)
library(ggplot2);library(caret);library(dplyr);library(rpart);library(rpart.plot)
treeModel <- rpart(classe ~ ., data=training, method="class")
fancyRpartPlot(treeModel)
library(ggplot2);library(caret);library(dplyr);library(rpart);library(rattle)
treeModel <- rpart(classe ~ ., data=training, method="class")
fancyRpartPlot(treeModel)
predTree <- predict(treeModel, newdata = validation, type="class")
confusionMatrix(predTree, validation$classe)
rfModel <- train(classe ~ ., data=training, method="RF")
rfModel <- train(classe ~ ., data=training, method="rf")
library(ggplot2);library(caret);library(dplyr);library(rpart);library(rattle);
library(randomForest)
#rfModel <- train(classe ~ ., data=training, method="rf")
rfModel <- randomForest(classe~.,data=training)
#rfModel <- train(classe ~ ., data=training, method="rf")
rfModel <- randomForest(classe~.,data=training)
predRF <- predict(rfModel, newdata = validation, type="class")
confusionMatrix(predRF, validation$classe)
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
rfModel <- randomForest(classe~.,data=training, trControl=trctrl)
predRF <- predict(rfModel, newdata = validation, type="class")
confusionMatrix(predRF, validation$classe)
svmModel <- train(classe~.,data=training, trControl=trctrl, method="SVMLinear")
svmModel <- train(classe~.,data=training, trControl=trctrl, method="svmLinear")
predSVM <- predict(rfModel, newdata = validation, type="class")
confusionMatrix(predSVM, validation$classe)
View(rfModel)
library(ggplot2);library(caret);library(dplyr);library(rpart);library(rattle);
library(randomForest)
plot(training$classe, rfModel$predicted)
plot(training$classe~rfModel$predicted)
qplot(training$classe~rfModel$predicted)
qplot(x=training$classe,y=rfModel$predicted)
qplot(preSVM,classe, data=validation)
qplot(predSVM,classe, data=validation)
qqplot(predSVM)
plot(predSVM)
plot(predSVM, validation$classe)
trctrl2 <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
svmModel <- train(classe~.,data=training, trControl=trctrl2, method="svmLinear")
predSVM <- predict(rfModel, newdata = validation, type="class")
confusionMatrix(predSVM, validation$classe)
test <- test[, -c(nsv,c(1:5))]
test <- test[,rNas < .75]
predTree <- predict(treeModel, newdata = validation, type="class")
confusionMatrix(predTree, validation$classe)
predRF <- predict(rfModel, newdata = validation, type="class")
confusionMatrix(predRF, validation$classe)
predSVM <- predict(rfModel, newdata = validation, type="class")
confusionMatrix(predSVM, validation$classe)
predSVM <- predict(svmModel, newdata = validation, type="class")
predSVM <- predict(svmModel, newdata = validation)
confusionMatrix(predSVM, validation$classe)
results <- resamples(list(model=rfModel,treeModel, svmModel))
results <- resamples(list(model=rfModel, svmModel))
results <- resamples(list(model=rfModel, treeModel))
results <- resamples(list(rf=rfModel, treeModel))
trctrl2 <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
gbmModel <- train(classe~.,data=training, trControl=trctrl2, method="gbm")
predGBM <- predict(gbmModel, newdata = validation)
confusionMatrix(predGBM, validation$classe)
trctrl2 <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
gbmModel <- train(classe~.,data=training, trControl=trctrl2, method="lgbm")
trctrl2 <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
gbmModel <- train(classe~.,data=training, trControl=trctrl2, method=caretModel.LGBM())
library(ggplot2);library(caret);library(dplyr);library(rpart);library(rattle);
library(randomForest);require(RLightGBM)
install.packages("rlightgbm")
install.packages("lightgbm")
MDSplot(rfModel, validation$classe)
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
rfModel <- randomForest(classe~.,data=training, trControl=trctrl, proximity=T)
predRF <- predict(rfModel, newdata = validation, type="class")
confusionMatrix(predRF, validation$classe)
MDSplot(rfModel, validation$classe)
MDSplot(rfModel, validation$classe)
library(ggplot2);library(caret);library(dplyr);library(rpart);library(rattle);
library(randomForest);
MDSplot(rfModel, validation$classe)
MDSplot(rfModel, validation$classe, k=2)
library(ggplot2);library(caret);library(dplyr);library(rpart);library(rattle);
library(randomForest);library(gbm)
install.packages("corrplot")
library(knitr)
setwd("~/curso r/curso 8")
knit("MLProject.Rmd")
